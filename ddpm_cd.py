import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.distributed as dist  # åˆ†å¸ƒå¼è®­ç»ƒ
import torch.multiprocessing as mp  # å¤šè¿›ç¨‹
from torch.nn.parallel import DistributedDataParallel as DDP  # åˆ†å¸ƒå¼DataParallel
from torch.utils.data.distributed import DistributedSampler  # åˆ†å¸ƒå¼é‡‡æ ·å™¨

import data as Data
import model as Model
import argparse
import logging
import core.logger as Logger
import core.metrics as Metrics
from core.wandb_logger import WandbLogger
from tensorboardX import SummaryWriter
import os
import numpy as np
from model.cd_modules.cd_head import cd_head 
from misc.print_diffuse_feats import print_feats
import time
from contextlib import contextmanager
import csv
import sys
import inspect
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # ä½¿ç”¨4ä¸ªGPU
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # åŒæ­¥CUDAè°ƒç”¨ï¼Œä¾¿äºè°ƒè¯•

# ==================== ä¼˜åŒ–ç‰ˆæ ‡ç­¾éªŒè¯å™¨ ====================
# ä¿®æ”¹ LabelValidator ç±»ï¼Œä½¿å…¶ä¹Ÿèƒ½å¤„ç†ç‰©ç†æ•°æ®

class LabelValidator:
    """é«˜æ•ˆæ ‡ç­¾éªŒè¯å™¨ - å•ä¾‹æ¨¡å¼"""
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not self._initialized:
            self.is_normalized = None
            self.validation_done = False
            self.label_stats = {}
            self.physical_data_validated = False  # æ–°å¢ï¼šç‰©ç†æ•°æ®éªŒè¯æ ‡å¿—
            LabelValidator._initialized = True
    
    def validate_and_fix_labels(self, data, phase="train"):
        """
        é«˜æ•ˆæ ‡ç­¾éªŒè¯ - åªåœ¨ç¬¬ä¸€æ¬¡è¯¦ç»†æ£€æŸ¥ï¼Œåç»­å¿«é€Ÿå¤„ç†
        """
        if 'L' not in data:
            return False
        
        labels = data['L']
        
        # å¿«é€Ÿé€šé“ï¼šå¦‚æœå·²ç»éªŒè¯è¿‡ï¼Œç›´æ¥å¤„ç†
        if self.validation_done:
            if self.is_normalized:
                data['L'] = (labels >= 0.5).long()
            else:
                # This 'fixed_labels' is local to this block and does not cause issues.
                fixed_labels = labels.clone()
                if 255 in torch.unique(labels):
                    fixed_labels[labels == 255] = 1
                data['L'] = torch.clamp(fixed_labels, 0, 1).long()
            
            # æ–°å¢ï¼šä¸ºæ–°CDæ¨¡å‹æ·»åŠ labelå­—æ®µ
            data['label'] = data['L']
            return True
        
        # --- ç¬¬ä¸€æ¬¡è¯¦ç»†éªŒè¯ (ä»æ‚¨çš„åŸå§‹å‡½æ•°ä¸­å®Œæ•´æ¢å¤) ---
        unique_vals = torch.unique(labels)
        min_val, max_val = labels.min().item(), labels.max().item()
        
        print(f"\nğŸ” [{phase}] æ ‡ç­¾éªŒè¯ï¼ˆä»…æ˜¾ç¤ºä¸€æ¬¡ï¼‰:")
        print(f"   å½¢çŠ¶: {labels.shape}, æ•°æ®ç±»å‹: {labels.dtype}")
        print(f"   å€¼èŒƒå›´: [{min_val}, {max_val}]")
        print(f"   å”¯ä¸€å€¼: {unique_vals.tolist()}")
        
        # åˆ¤æ–­æ ‡ç­¾ç±»å‹å¹¶è¿›è¡Œä¿®å¤
        self.is_normalized = (max_val <= 1.0 and min_val >= 0.0)
        
        if self.is_normalized:
            print("   ğŸ”§ æ£€æµ‹åˆ°å½’ä¸€åŒ–æ ‡ç­¾ï¼Œä½¿ç”¨é˜ˆå€¼äºŒå€¼åŒ–ï¼ˆé˜ˆå€¼=0.5ï¼‰")
            fixed_labels = (labels >= 0.5).long()
        else:
            print("   ğŸ”§ æ£€æµ‹åˆ°æ ‡å‡†æ ‡ç­¾ï¼Œæ˜ å°„255â†’1")
            fixed_labels = labels.clone()
            if 255 in unique_vals:
                fixed_labels[labels == 255] = 1
            fixed_labels = torch.clamp(fixed_labels, 0, 1).long()
        
        # éªŒè¯ä¿®å¤ç»“æœå¹¶æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        final_unique = torch.unique(fixed_labels)
        zero_count = (fixed_labels == 0).sum().item()
        one_count = (fixed_labels == 1).sum().item()
        total_pixels = fixed_labels.numel()
        
        if total_pixels > 0:
            print(f"   âœ… ä¿®å¤å®Œæˆ: å”¯ä¸€å€¼{final_unique.tolist()}")
            print(f"   ğŸ“Š åƒç´ åˆ†å¸ƒ: æ— å˜åŒ–={100 * zero_count / total_pixels:.1f}%, æœ‰å˜åŒ–={100 * one_count / total_pixels:.1f}%")
        print("   âœ… æ ‡ç­¾éªŒè¯è®¾ç½®å®Œæˆï¼Œåç»­æ‰¹æ¬¡å°†å¿«é€Ÿå¤„ç†\n")
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        if total_pixels > 0:
            self.label_stats = {
                'zero_ratio': zero_count / total_pixels,
                'one_ratio': one_count / total_pixels,
                'is_normalized': self.is_normalized
            }
        
        # å°†ä¿®å¤åçš„æ ‡ç­¾åº”ç”¨åˆ°æ•°æ®å­—å…¸ä¸­
        data['L'] = fixed_labels
        # æ–°å¢ï¼šåŒæ—¶è®¾ç½®labelå­—æ®µä»¥é€‚é…æ–°æ¨¡å‹
        data['label'] = fixed_labels
        
        self.validation_done = True
        return True
    
    def validate_physical_data(self, data, phase="train"):
        """
        æ–°å¢ï¼šéªŒè¯ç‰©ç†æ•°æ®
        """
        if 'physical_data' not in data:
            return False
        
        if not self.physical_data_validated:
            physical = data['physical_data']
            print(f"\nğŸ” [{phase}] ç‰©ç†æ•°æ®éªŒè¯ï¼ˆä»…æ˜¾ç¤ºä¸€æ¬¡ï¼‰:")
            print(f"   å½¢çŠ¶: {physical.shape}, æ•°æ®ç±»å‹: {physical.dtype}")
            print(f"   é€šé“æ•°: {physical.shape[1]}")
            
            # æ‰“å°æ¯ä¸ªé€šé“çš„ä¿¡æ¯
            channel_names = ['DEM', 'å¡åº¦', 'å¡å‘', 'åœ°è´¨ç±»å‹', 'æ¤è¢«è¦†ç›–']
            for i in range(min(physical.shape[1], len(channel_names))):
                channel_data = physical[:, i]
                print(f"   é€šé“{i} ({channel_names[i]}): "
                      f"èŒƒå›´[{channel_data.min():.2f}, {channel_data.max():.2f}]")
            
            self.physical_data_validated = True
            print("   âœ… ç‰©ç†æ•°æ®éªŒè¯å®Œæˆ\n")
        
        return True

# å…¨å±€æ ‡ç­¾éªŒè¯å™¨
label_validator = LabelValidator()

# ==================== å†…å­˜ç®¡ç†å·¥å…· ====================
@contextmanager
def memory_efficient_context():
    """å†…å­˜ç®¡ç†ä¸Šä¸‹æ–‡"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    try:
        yield
    finally:
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    def __init__(self):
        self.step_times = []
        self.memory_usage = []
        self.start_time = time.time()
    
    def log_step(self, step_time, memory_mb=None):
        self.step_times.append(step_time)
        if memory_mb:
            self.memory_usage.append(memory_mb)
    
    def get_stats(self):
        if not self.step_times:
            return "æ— ç»Ÿè®¡æ•°æ®"
        
        avg_time = np.mean(self.step_times[-100:])  # æœ€è¿‘100æ­¥å¹³å‡
        total_time = time.time() - self.start_time
        
        stats = f"å¹³å‡æ­¥æ—¶: {avg_time:.2f}s, æ€»æ—¶é—´: {total_time/60:.1f}min"
        
        if self.memory_usage:
            avg_memory = np.mean(self.memory_usage[-10:])
            stats += f", æ˜¾å­˜: {avg_memory:.1f}MB"
        
        return stats
    
# ==================== å…¼å®¹æ€§è¾…åŠ©å‡½æ•° ====================
def ensure_cd_model_compatibility(change_detection, opt):
    """
    ç¡®ä¿CDæ¨¡å‹å…·æœ‰æ‰€æœ‰å¿…éœ€çš„æ–¹æ³•å’Œå±æ€§
    """
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ªå™¨
    if not hasattr(change_detection, 'running_metric'):
        from misc.metric_tools import ConfuseMatrixMeter
        change_detection.running_metric = ConfuseMatrixMeter(n_class=opt['model_cd']['out_channels'])
        print("âœ… æ·»åŠ äº†æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ªå™¨")
    
    # ç¡®ä¿æœ‰log_dict
    if not hasattr(change_detection, 'log_dict'):
        change_detection.log_dict = OrderedDict()
    
    # æ·»åŠ å¿…è¦çš„æ–¹æ³•
    if not hasattr(change_detection, '_clear_cache'):
        change_detection._clear_cache = lambda: change_detection.running_metric.clear() if hasattr(change_detection, 'running_metric') else None
    
    if not hasattr(change_detection, '_update_metric'):
        def _update_metric():
            if hasattr(change_detection, 'change_prediction') and hasattr(change_detection, 'label'):
                G_pred = change_detection.change_prediction.detach()
                G_pred = torch.argmax(G_pred, dim=1)
                current_score = change_detection.running_metric.update_cm(
                    pr=G_pred.cpu().numpy(), 
                    gt=change_detection.label.detach().cpu().numpy()
                )
                return current_score
            return 0.0
        change_detection._update_metric = _update_metric
    
    if not hasattr(change_detection, '_collect_running_batch_states'):
        def _collect_running_batch_states():
            change_detection.running_acc = change_detection._update_metric()
            change_detection.log_dict['running_acc'] = change_detection.running_acc.item() if hasattr(change_detection.running_acc, 'item') else change_detection.running_acc
        change_detection._collect_running_batch_states = _collect_running_batch_states
    
    if not hasattr(change_detection, '_collect_epoch_states'):
        def _collect_epoch_states():
            scores = change_detection.running_metric.get_scores()
            change_detection.epoch_acc = scores['mf1']
            change_detection.log_dict['epoch_acc'] = change_detection.epoch_acc.item() if hasattr(change_detection.epoch_acc, 'item') else change_detection.epoch_acc
            for k, v in scores.items():
                change_detection.log_dict[k] = v
        change_detection._collect_epoch_states = _collect_epoch_states
    
    if not hasattr(change_detection, '_update_lr_schedulers'):
        def _update_lr_schedulers():
            if hasattr(change_detection, 'schedulers'):
                for scheduler in change_detection.schedulers:
                    scheduler.step()
            elif hasattr(change_detection, 'exp_lr_scheduler_netCD'):
                change_detection.exp_lr_scheduler_netCD.step()
            elif hasattr(change_detection, 'optimizer'):
                # å¦‚æœæ²¡æœ‰è°ƒåº¦å™¨ä½†æœ‰ä¼˜åŒ–å™¨ï¼Œåˆ›å»ºä¸€ä¸ª
                from misc.torchutils import get_scheduler
                change_detection.exp_lr_scheduler_netCD = get_scheduler(
                    optimizer=change_detection.optimizer, 
                    args=opt['train']
                )
                change_detection.exp_lr_scheduler_netCD.step()
        change_detection._update_lr_schedulers = _update_lr_schedulers
    
    # ç¡®ä¿save_networkæ–¹æ³•
    if not hasattr(change_detection, 'save_network'):
        if hasattr(change_detection, 'save'):
            change_detection.save_network = lambda epoch, is_best_model=False: change_detection.save(epoch, is_best_model)
        else:
            print("âš ï¸  è­¦å‘Šï¼šCDæ¨¡å‹æ²¡æœ‰saveæˆ–save_networkæ–¹æ³•")
    
    return change_detection

# ==================== æ–°å¢ï¼šå•æ ·æœ¬æŒ‡æ ‡è®¡ç®—å‡½æ•° ====================
def calculate_per_sample_metrics(pred_tensor, label_tensor):
    """
    è®¡ç®—å•ä¸ªæ ·æœ¬çš„æ€§èƒ½æŒ‡æ ‡ã€‚
    è¾“å…¥æ˜¯å•ä¸ª[H, W]çš„é¢„æµ‹å’Œæ ‡ç­¾å¼ é‡ï¼ˆå€¼ä¸º0æˆ–1ï¼‰ã€‚
    """
    metrics = {}
    
    # ç¡®ä¿å¼ é‡æ˜¯å¸ƒå°”ç±»å‹ä»¥ä¾¿è¿›è¡Œé€»è¾‘è¿ç®—
    pred = pred_tensor.bool()
    label = label_tensor.bool()

    # åŸºæœ¬ç»Ÿè®¡é‡
    tp = (pred & label).sum().item()
    fp = (pred & ~label).sum().item()
    fn = (~pred & label).sum().item()
    tn = (~pred & ~label).sum().item()
    
    # é˜²æ­¢é™¤ä»¥é›¶
    epsilon = 1e-6

    # --- å˜åŒ–ç±»åˆ« (Class 1) ---
    precision_1 = tp / (tp + fp + epsilon)
    recall_1 = tp / (tp + fn + epsilon)
    f1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1 + epsilon)
    iou_1 = tp / (tp + fp + fn + epsilon)
    
    # --- æ— å˜åŒ–ç±»åˆ« (Class 0) ---
    precision_0 = tn / (tn + fn + epsilon)
    recall_0 = tn / (tn + fp + epsilon)
    f1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0 + epsilon)
    iou_0 = tn / (tn + fp + epsilon)
    
    # --- æ€»ä½“æŒ‡æ ‡ ---
    oa = (tp + tn) / (tp + tn + fp + fn + epsilon)
    mf1 = (f1_1 + f1_0) / 2
    miou = (iou_1 + iou_0) / 2
    
    # è¿”å›å­—å…¸
    return {
        'OA': oa,
        'mF1': mf1,
        'mIoU': miou,
        'F1_change': f1_1,
        'IoU_change': iou_1,
        'Precision_change': precision_1,
        'Recall_change': recall_1,
        'F1_no_change': f1_0,
        'IoU_no_change': iou_0,
        'Precision_no_change': precision_0,
        'Recall_no_change': recall_0,
    }

# ==================== ä¼˜åŒ–ç‰ˆç‰¹å¾é‡æ’ ====================
def apply_feature_reordering_optimized(f_A, f_B, train_data, change_detection, opt, phase="train"):
    """
    å†…å­˜ä¼˜åŒ–çš„ç‰¹å¾é‡æ’æ–¹æ¡ˆ - é€‚é…æ–°CDæ¨¡å‹æ¥å£
    """
    try:
        feat_scales = opt['model_cd']['feat_scales']  # [2, 5, 8, 11, 14]
        cd_expected_order = sorted(feat_scales, reverse=True)  # [14, 11, 8, 5, 2]
        
        # åªåœ¨ç¬¬ä¸€æ¬¡æ˜¾ç¤ºä¿¡æ¯
        if not hasattr(apply_feature_reordering_optimized, '_logged'):
            print("ğŸ¯ ä½¿ç”¨ä¼˜åŒ–çš„ç‰¹å¾é‡æ’æ–¹æ¡ˆ")
            print("   ä¿æŒåŸå§‹å¤šå°ºåº¦é…ç½®çš„å®Œæ•´è¯­ä¹‰")
            for i, scale in enumerate(cd_expected_order):
                print(f"     Block{i}: ä½¿ç”¨layer{scale}ç‰¹å¾")
            apply_feature_reordering_optimized._logged = True
        
        # é«˜æ•ˆé‡æ’ï¼šç›´æ¥åœ¨åŸåœ°ä¿®æ”¹
        reordered_f_A = []
        reordered_f_B = []
        
        for fa, fb in zip(f_A, f_B):
            if isinstance(fa, list) and len(fa) > max(feat_scales):
                timestep_A = [fa[scale] for scale in cd_expected_order]
                timestep_B = [fb[scale] for scale in cd_expected_order]
                reordered_f_A.append(timestep_A)
                reordered_f_B.append(timestep_B)
            else:
                raise ValueError(f"ç‰¹å¾æ ¼å¼é”™è¯¯: æœŸæœ›listé•¿åº¦>{max(feat_scales)}, å®é™…{type(fa)}")
        
        # æ¸…ç†åŸå§‹ç‰¹å¾é‡Šæ”¾å†…å­˜
        del f_A, f_B
        
        # æ–°CDæ¨¡å‹æ¥å£é€‚é…
        if hasattr(change_detection, 'feed_data'):
            # æ–°æ¨¡å‹ä½¿ç”¨å•ä¸€feed_dataæ¥å£
            change_detection.feed_data(train_data)
            # ä¿å­˜ç‰¹å¾ä¾›åç»­ä½¿ç”¨
            change_detection._temp_features_A = reordered_f_A
            change_detection._temp_features_B = reordered_f_B
        else:
            # æ—§æ¨¡å‹æ¥å£
            change_detection.feed_data(reordered_f_A, reordered_f_B, train_data)
        
        # æ¸…ç†é‡æ’åçš„ç‰¹å¾
        del reordered_f_A, reordered_f_B
        
        return True
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾é‡æ’å¤±è´¥: {e}")
        print("ğŸ”„ ä½¿ç”¨å›é€€æ–¹æ¡ˆ...")
        
        # ç®€åŒ–å›é€€æ–¹æ¡ˆï¼ˆåŒæ ·é€‚é…æ–°æ¥å£ï¼‰
        target_layers = [12, 13, 14]
        corrected_f_A = []
        corrected_f_B = []
        
        for fa, fb in zip(f_A, f_B):
            timestep_A = [fa[i] for i in target_layers if i < len(fa)]
            timestep_B = [fb[i] for i in target_layers if i < len(fb)]
            corrected_f_A.append(timestep_A)
            corrected_f_B.append(timestep_B)
        
        del f_A, f_B
        
        if hasattr(change_detection, 'feed_data') and hasattr(change_detection, '_temp_features_A'):
            change_detection.feed_data(train_data)
            change_detection._temp_features_A = corrected_f_A
            change_detection._temp_features_B = corrected_f_B
        else:
            change_detection.feed_data(corrected_f_A, corrected_f_B, train_data)
        
        del corrected_f_A, corrected_f_B
        
        return False

# ==================== è®­ç»ƒä¼˜åŒ–è®¾ç½® ====================
def setup_training_optimization(diffusion, change_detection):
    """è®¾ç½®è®­ç»ƒä¼˜åŒ–"""
    print("ğŸš€ è®¾ç½®è®­ç»ƒä¼˜åŒ–...")
    
    # å¯ç”¨CUDAä¼˜åŒ–
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False
    
    # æ£€æŸ¥æ··åˆç²¾åº¦æ”¯æŒ
    use_amp = False
    if torch.cuda.is_available():
        try:
            from torch.cuda.amp import autocast, GradScaler
            use_amp = True
            print("   âœ… æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ")
        except ImportError:
            print("   âš ï¸  ä¸æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ")
    
    # è®¾ç½®diffusionæ¨¡å‹ä¸ºevalæ¨¡å¼ï¼ˆå¦‚æœä¸éœ€è¦è®­ç»ƒï¼‰
    if hasattr(diffusion.netG, 'eval'):
        diffusion.netG.eval()
        print("   âœ… Diffusionæ¨¡å‹è®¾ç½®ä¸ºevalæ¨¡å¼")
    
    # æ£€æŸ¥å¤šGPUè®¾ç½®
    if torch.cuda.device_count() > 1:
        print(f"   âœ… æ£€æµ‹åˆ°{torch.cuda.device_count()}ä¸ªGPU")
        
        # æ˜¾ç¤ºGPUçŠ¶æ€
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            memory_gb = props.total_memory / 1024**3
            print(f"     GPU {i}: {props.name} ({memory_gb:.1f}GB)")
    
    print("ğŸš€ è®­ç»ƒä¼˜åŒ–è®¾ç½®å®Œæˆ\n")
    
    return use_amp

# ==================== æ‰¹é‡å¤„ç†ä¼˜åŒ– ====================
# def process_batch_efficiently(train_data, diffusion, change_detection, opt, phase="train"):
#     """é«˜æ•ˆçš„æ‰¹é‡å¤„ç†"""
#     with memory_efficient_context():
#         # 1. å¿«é€Ÿæ ‡ç­¾éªŒè¯
#         label_validator.validate_and_fix_labels(train_data, phase)
        
#         # 2. ç‰¹å¾æå–
#         diffusion.feed_data(train_data)
        
#         # 3. æ”¶é›†ç‰¹å¾
#         f_A, f_B = [], []
#         for t in opt['model_cd']['t']:
#             fe_A_t, fd_A_t, fe_B_t, fd_B_t = diffusion.get_feats(t=t)
#             if opt['model_cd']['feat_type'] == "dec":
#                 f_A.append(fd_A_t)
#                 f_B.append(fd_B_t)
#                 del fe_A_t, fe_B_t  # ç«‹å³æ¸…ç†
#             else:
#                 f_A.append(fe_A_t)
#                 f_B.append(fe_B_t)
#                 del fd_A_t, fd_B_t  # ç«‹å³æ¸…ç†
        
#         # 4. ç‰¹å¾é‡æ’
#         apply_feature_reordering_optimized(f_A, f_B, train_data, change_detection, opt, phase)

def process_features_for_cd(change_detection, features_A, features_B, data, current_epoch=None, phase='train'):
    """
    ç»Ÿä¸€å¤„ç†ç‰¹å¾å¹¶è°ƒç”¨CDæ¨¡å‹çš„ç›¸åº”æ–¹æ³•
    """
    try:
        # æ–¹æ¡ˆ1ï¼šæ–°æ¨¡å‹æ¥å£ï¼ˆå•ä¸€feed_data + ä¸´æ—¶ç‰¹å¾ï¼‰
        if hasattr(change_detection, 'feed_data') and len(inspect.signature(change_detection.feed_data).parameters) == 2:
            # æ–°æ¥å£ï¼šfeed_dataåªæ¥å—ä¸€ä¸ªdataå‚æ•°
            change_detection.feed_data(data)
            
            if phase == 'train':
                # è®­ç»ƒé˜¶æ®µ
                if hasattr(change_detection.optimize_parameters, '__code__'):
                    params = change_detection.optimize_parameters.__code__.co_varnames
                    if 'features_A' in params or len(params) > 1:
                        # æ–°æ¥å£ï¼šéœ€è¦ç‰¹å¾
                        change_detection.optimize_parameters(features_A, features_B, current_epoch=current_epoch)
                    else:
                        # ç‰¹å¾å·²ç»åœ¨feed_dataä¸­å¤„ç†
                        change_detection._temp_features_A = features_A
                        change_detection._temp_features_B = features_B
                        change_detection.optimize_parameters()
                else:
                    change_detection._temp_features_A = features_A
                    change_detection._temp_features_B = features_B
                    change_detection.optimize_parameters()
            else:
                # éªŒè¯/æµ‹è¯•é˜¶æ®µ
                if hasattr(change_detection, 'test'):
                    if hasattr(change_detection.test, '__code__'):
                        params = change_detection.test.__code__.co_varnames
                        if 'features_A' in params or len(params) > 1:
                            change_detection.test(features_A, features_B)
                        else:
                            change_detection._temp_features_A = features_A
                            change_detection._temp_features_B = features_B
                            change_detection.test()
                    else:
                        change_detection.test()
        
        # æ–¹æ¡ˆ2ï¼šæ—§æ¨¡å‹æ¥å£ï¼ˆfeed_dataæ¥å—ä¸‰ä¸ªå‚æ•°ï¼‰
        else:
            change_detection.feed_data(features_A, features_B, data)
            if phase == 'train':
                change_detection.optimize_parameters()
            else:
                change_detection.test()
        
        # æ¸…ç†ä¸´æ—¶ç‰¹å¾
        if hasattr(change_detection, '_temp_features_A'):
            del change_detection._temp_features_A
        if hasattr(change_detection, '_temp_features_B'):
            del change_detection._temp_features_B
            
    except Exception as e:
        print(f"âŒ ç‰¹å¾å¤„ç†é”™è¯¯ ({phase}): {e}")
        import traceback
        traceback.print_exc()
        raise

def process_batch_efficiently(train_data, diffusion, change_detection, opt, phase="train", current_epoch=None):
    """é«˜æ•ˆçš„æ‰¹é‡å¤„ç† - å®Œæ•´ç‰ˆ"""
    with memory_efficient_context():
        try:
            # 1. æ ‡ç­¾éªŒè¯å’Œé€‚é…
            label_validator.validate_and_fix_labels(train_data, phase)
            
            # 2. ç‰©ç†æ•°æ®éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if opt['datasets'][phase].get('load_physical_data', False):
                label_validator.validate_physical_data(train_data, phase)
            
            # 3. è®¾å¤‡ä¸€è‡´æ€§
            device = next(diffusion.netG.parameters()).device
            for key, value in train_data.items():
                if torch.is_tensor(value):
                    train_data[key] = value.to(device)
            
            # 4. Diffusionç‰¹å¾æå–
            diffusion.feed_data(train_data)
            
            # 5. æ”¶é›†å¤šæ—¶é—´æ­¥ç‰¹å¾
            f_A, f_B = [], []
            for t in opt['model_cd']['t']:
                fe_A_t, fd_A_t, fe_B_t, fd_B_t = diffusion.get_feats(t=t)
                if opt['model_cd']['feat_type'] == "dec":
                    f_A.append(fd_A_t)
                    f_B.append(fd_B_t)
                    del fe_A_t, fe_B_t
                else:
                    f_A.append(fe_A_t)
                    f_B.append(fe_B_t)
                    del fd_A_t, fd_B_t
            
            # 6. ç‰¹å¾é‡æ’
            feat_scales = opt['model_cd']['feat_scales']
            cd_expected_order = sorted(feat_scales, reverse=True)
            
            reordered_f_A = []
            reordered_f_B = []
            
            for fa, fb in zip(f_A, f_B):
                if isinstance(fa, list) and len(fa) > max(feat_scales):
                    timestep_A = [fa[scale] for scale in cd_expected_order]
                    timestep_B = [fb[scale] for scale in cd_expected_order]
                    reordered_f_A.append(timestep_A)
                    reordered_f_B.append(timestep_B)
            
            # 7. è°ƒç”¨CDæ¨¡å‹
            process_features_for_cd(change_detection, reordered_f_A, reordered_f_B, 
                                  train_data, current_epoch, phase)
            
            # 8. æ¸…ç†å†…å­˜
            del f_A, f_B, reordered_f_A, reordered_f_B
            
        except Exception as e:
            print(f"âŒ æ‰¹å¤„ç†å¤±è´¥ ({phase}): {e}")
            import traceback
            traceback.print_exc()
            # å°è¯•æ¢å¤
            torch.cuda.empty_cache()
            raise


# ==================== ä¼˜åŒ–çš„æ—¥å¿—ç®¡ç† ====================
def optimized_logging(current_step, current_epoch, n_epoch, loader, change_detection, 
                     logger, opt, phase="train", performance_monitor=None):
    """ä¼˜åŒ–çš„æ—¥å¿—è¾“å‡º - å¢åŠ ç‰©ç†æŸå¤±ä¿¡æ¯"""
    # åŠ¨æ€è°ƒæ•´æ—¥å¿—é¢‘ç‡
    if phase == "train":
        base_freq = opt['train'].get('train_print_freq', 10)
        log_freq = max(base_freq, len(loader) // 1000)  # è‡³å°‘æ¯5%æ˜¾ç¤ºä¸€æ¬¡
    else:
        log_freq = max(1, len(loader) // 500)  # éªŒè¯æ—¶æ¯10%æ˜¾ç¤ºä¸€æ¬¡
    
    if current_step % log_freq == 0:
        try:
            logs = change_detection.get_current_log()
            
            # åŸºç¡€ä¿¡æ¯
            progress = f"[{current_epoch}/{n_epoch-1}]"
            step_info = f"Step {current_step}/{len(loader)}"
            
            # æ„å»ºæŒ‡æ ‡ä¿¡æ¯
            loss_info = f"Loss: {logs.get('l_cd', 0):.5f}"
            
            # å¦‚æœæœ‰ç‰©ç†æŸå¤±çš„è¯¦ç»†ä¿¡æ¯ï¼Œä¹Ÿæ˜¾ç¤º
            if 'physics_loss' in logs:
                loss_info += f" (CE: {logs.get('ce_loss', 0):.3f}, Phy: {logs.get('physics_loss', 0):.3f})"
            
            metrics = f"{loss_info} mF1: {logs.get('running_acc', 0):.5f}"
            
            # æ€§èƒ½ä¿¡æ¯
            perf_info = ""
            if performance_monitor:
                perf_info = f" | {performance_monitor.get_stats()}"
            
            message = f"{progress} {step_info} {metrics}{perf_info}"
            print(message)
            
        except Exception as e:
            print(f"æ—¥å¿—è¾“å‡ºé”™è¯¯: {e}")


# ==================== é”™è¯¯å¤„ç†è£…é¥°å™¨ ====================
def safe_training_step(func):
    """å®‰å…¨è®­ç»ƒæ­¥éª¤è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except RuntimeError as e:
            if "device-side assert triggered" in str(e) or "CUDA" in str(e):
                print(f"âš ï¸  CUDAé”™è¯¯å·²è‡ªåŠ¨å¤„ç†: {str(e)[:100]}...")
                torch.cuda.empty_cache()
                return False
            else:
                raise
        except Exception as e:
            print(f"âŒ è®­ç»ƒæ­¥éª¤é”™è¯¯: {e}")
            return False
    return wrapper

@safe_training_step
def execute_training_step(change_detection, current_epoch=None):
    """æ‰§è¡Œè®­ç»ƒæ­¥éª¤ - é€‚é…æ–°æ¥å£"""
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸´æ—¶ä¿å­˜çš„ç‰¹å¾
    if hasattr(change_detection, '_temp_features_A') and hasattr(change_detection, '_temp_features_B'):
        # æ–°æ¥å£ï¼šéœ€è¦ä¼ å…¥ç‰¹å¾å’Œepoch
        change_detection.optimize_parameters(
            change_detection._temp_features_A,
            change_detection._temp_features_B,
            current_epoch=current_epoch
        )
        # æ¸…ç†ä¸´æ—¶ç‰¹å¾
        del change_detection._temp_features_A
        del change_detection._temp_features_B
    else:
        # æ—§æ¥å£ï¼šæ— å‚æ•°
        change_detection.optimize_parameters()
    
    change_detection._collect_running_batch_states()
    return True

# ==================== ä¸»å‡½æ•° ====================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('-c', '--config', type=str, default='config/ddpm_cd.json',
                        help='JSON file for configuration')
    parser.add_argument('-p', '--phase', type=str, choices=['train', 'test'],
                        help='Run either train(training + validation) or testing', default='train')
    parser.add_argument('-gpu', '--gpu_ids', type=str, default=None)
    parser.add_argument('-debug', '-d', action='store_true')
    parser.add_argument('-enable_wandb', action='store_true')
    parser.add_argument('-log_eval', action='store_true')

    # æ–°å¢ï¼šç‰©ç†æŸå¤±ç›¸å…³å‚æ•°
    parser.add_argument('--use_physics_loss', action='store_true',
                        help='Enable physics-constrained loss')
    parser.add_argument('--physics_config', type=str, default=None,
                        help='Override physics loss config file')
    parser.add_argument('--no_progressive', action='store_true',
                        help='Disable progressive training for physics loss')

    # è§£æé…ç½®
    args = parser.parse_args()
    opt = Logger.parse(args)

    # å¦‚æœå‘½ä»¤è¡ŒæŒ‡å®šä½¿ç”¨ç‰©ç†æŸå¤±ï¼Œè¦†ç›–é…ç½®æ–‡ä»¶
    if args.use_physics_loss:
        opt['model_cd']['loss_type'] = 'physics_constrained'
        print("ğŸ”§ å‘½ä»¤è¡Œå‚æ•°ï¼šå¯ç”¨ç‰©ç†çº¦æŸæŸå¤±")
    
    # å¦‚æœæŒ‡å®šäº†ç‰©ç†æŸå¤±é…ç½®æ–‡ä»¶ï¼ŒåŠ è½½å¹¶åˆå¹¶
    if args.physics_config:
        import json
        with open(args.physics_config, 'r') as f:
            physics_config = json.load(f)
            if 'physics_loss' in physics_config:
                opt['model_cd']['physics_loss'] = physics_config['physics_loss']
                print(f"ğŸ”§ åŠ è½½ç‰©ç†æŸå¤±é…ç½®: {args.physics_config}")
    
    # æ™ºèƒ½é€‰æ‹©é…ç½®æ–‡ä»¶
    if args.config == 'config/ddpm_cd.json' and args.use_physics_loss:
        # å¦‚æœä½¿ç”¨é»˜è®¤é…ç½®ä½†æŒ‡å®šäº†ç‰©ç†æŸå¤±ï¼Œå°è¯•ä½¿ç”¨ç‰©ç†æŸå¤±é…ç½®æ–‡ä»¶
        physics_config_path = 'config/gvlm_cd_physical.json'
        if os.path.exists(physics_config_path):
            args.config = physics_config_path
            print(f"ğŸ”§ è‡ªåŠ¨åˆ‡æ¢åˆ°ç‰©ç†æŸå¤±é…ç½®æ–‡ä»¶: {physics_config_path}")
        else:
            print(f"âš ï¸  ç‰©ç†æŸå¤±é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {physics_config_path}")
            print("   å°†ä½¿ç”¨é»˜è®¤é…ç½®å¹¶åŠ¨æ€æ·»åŠ ç‰©ç†æŸå¤±è®¾ç½®")
    
    # å¦‚æœç¦ç”¨æ¸è¿›å¼è®­ç»ƒ
    if args.no_progressive and 'physics_loss' in opt['model_cd']:
        opt['model_cd']['physics_loss']['enable_progressive'] = False
        print("ğŸ”§ ç¦ç”¨æ¸è¿›å¼è®­ç»ƒ")
    
    # éªŒè¯é…ç½®å®Œæ•´æ€§
    if opt['model_cd'].get('loss_type') == 'physics_constrained':
        if 'physics_loss' not in opt['model_cd']:
            # æä¾›é»˜è®¤ç‰©ç†æŸå¤±é…ç½®
            opt['model_cd']['physics_loss'] = {
                'alpha': 0,
                'beta': 0.05,
                'gamma': 0.03,
                'delta': 0,
                'enable_progressive': True,
                'warmup_epochs': 10,
                'use_progressive': False
            }
            print("âš ï¸  ä½¿ç”¨é»˜è®¤ç‰©ç†æŸå¤±é…ç½®")
        
        # éªŒè¯æ•°æ®é›†é…ç½®
        for phase in ['train', 'val']:
            if phase in opt['datasets']:
                if not opt['datasets'][phase].get('load_physical_data', False):
                    print(f"âš ï¸  è­¦å‘Šï¼š{phase}æ•°æ®é›†æœªé…ç½®load_physical_dataï¼Œç‰©ç†æŸå¤±å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
                    opt['datasets'][phase]['load_physical_data'] = True

    opt = Logger.dict_to_nonedict(opt)

    # è®¾ç½®æ—¥å¿—
    torch.backends.cudnn.enabled = True
    torch.backends.cudnn.benchmark = True

    Logger.setup_logger(None, opt['path']['log'], 'train', level=logging.INFO, screen=True)
    Logger.setup_logger('test', opt['path']['log'], 'test', level=logging.INFO)
    logger = logging.getLogger('base')
    logger.info(Logger.dict2str(opt))
    # æ–°å¢ï¼šæ‰“å°å…³é”®é…ç½®æ‘˜è¦
    print("\n" + "="*50)
    print("ğŸ”§ å…³é”®é…ç½®æ‘˜è¦:")
    print("="*50)
    print(f"æ¨¡å‹åç§°: {opt.get('name', 'Unknown')}")
    print(f"è®­ç»ƒé˜¶æ®µ: {opt['phase']}")
    print(f"æŸå¤±ç±»å‹: {opt['model_cd'].get('loss_type', 'ce')}")
    
    if opt['model_cd'].get('loss_type') == 'physics_constrained':
        physics_cfg = opt['model_cd'].get('physics_loss', {})
        print(f"\nç‰©ç†æŸå¤±é…ç½®:")
        print(f"  - å¡åº¦çº¦æŸ (Î±): {physics_cfg.get('alpha', 0)}")
        print(f"  - ç©ºé—´è¿ç»­æ€§ (Î²): {physics_cfg.get('beta', 0)}")
        print(f"  - å°ºå¯¸çº¦æŸ (Î³): {physics_cfg.get('gamma', 0)}")
        print(f"  - åœ°è´¨çº¦æŸ (Î´): {physics_cfg.get('delta', 0)}")
        print(f"  - æ¸è¿›å¼è®­ç»ƒ: {physics_cfg.get('enable_progressive', True)}")
        print(f"  - é¢„çƒ­è½®æ¬¡: {physics_cfg.get('warmup_epochs', 10)}")
    
    print(f"\næ•°æ®é…ç½®:")
    for phase in ['train', 'val', 'test']:
        if phase in opt['datasets']:
            ds_cfg = opt['datasets'][phase]
            print(f"  {phase}:")
            print(f"    - æ‰¹é‡å¤§å°: {ds_cfg.get('batch_size', 'N/A')}")
            print(f"    - åŠ è½½ç‰©ç†æ•°æ®: {ds_cfg.get('load_physical_data', False)}")
            if ds_cfg.get('load_physical_data'):
                print(f"    - ç‰©ç†æ•°æ®è·¯å¾„: {ds_cfg.get('physical_data_path', 'Not specified')}")
    
    print(f"\nè®­ç»ƒé…ç½®:")
    print(f"  - æ€»è½®æ¬¡: {opt['train']['n_epoch']}")
    print(f"  - ä¼˜åŒ–å™¨: {opt['train']['optimizer']['type']}")
    print(f"  - å­¦ä¹ ç‡: {opt['train']['optimizer']['lr']}")
    print(f"  - GPUè®¾å¤‡: {opt['gpu_ids']}")
    print("="*50 + "\n")
    
    tb_logger = SummaryWriter(log_dir=opt['path']['tb_logger'])

    # åˆå§‹åŒ–WandbLogger
    if opt['enable_wandb']:
        import wandb
        print("Initializing wandblog.")
        
        # æ ¹æ®æ˜¯å¦ä½¿ç”¨ç‰©ç†æŸå¤±æ›´æ–°é¡¹ç›®åç§°
        if opt['model_cd'].get('loss_type') == 'physics_constrained':
            original_project = opt['wandb']['project']
            opt['wandb']['project'] = f"{original_project}-Physics"
            print(f"WandBé¡¹ç›®åç§°æ›´æ–°ä¸º: {opt['wandb']['project']}")
        
        wandb_logger = WandbLogger(opt)
        
        # è®°å½•é…ç½®ä¿¡æ¯
        wandb.config.update({
            'loss_type': opt['model_cd'].get('loss_type', 'ce'),
            'physics_loss': opt['model_cd'].get('physics_loss', {}),
            'load_physical_data': any(
                opt['datasets'][p].get('load_physical_data', False) 
                for p in opt['datasets']
            )
        })
        
        wandb.define_metric('epoch')
        wandb.define_metric('training/train_step')
        wandb.define_metric("training/*", step_metric="train_step")
        wandb.define_metric('validation/val_step')
        wandb.define_metric("validation/*", step_metric="val_step")
        
        # ç‰©ç†æŸå¤±ç›¸å…³æŒ‡æ ‡
        if opt['model_cd'].get('loss_type') == 'physics_constrained':
            wandb.define_metric("physics/*", step_metric="train_step")
        
        train_step = 0
        val_step = 0
    else:
        wandb_logger = None
        
    # åŠ è½½æ•°æ®é›†
    print("ğŸ”„ åŠ è½½æ•°æ®é›†...")
    for phase, dataset_opt in opt['datasets'].items():
         # æ£€æŸ¥æ˜¯å¦éœ€è¦åŠ è½½ç‰©ç†æ•°æ®
        if dataset_opt.get('load_physical_data', False):
            print(f"   ğŸ“Š {phase}æ•°æ®é›†å°†åŠ è½½ç‰©ç†æ•°æ®")
            physical_path = dataset_opt.get('physical_data_path', '')
            if not physical_path:
                print(f"   âš ï¸  è­¦å‘Šï¼š{phase}æ•°æ®é›†é…ç½®äº†load_physical_dataä½†æœªæŒ‡å®šphysical_data_path")
        if phase == 'train' and args.phase != 'test':
            print("Creating [train] change-detection dataloader.")
            train_set = Data.create_cd_dataset(dataset_opt, phase)
            train_loader = Data.create_cd_dataloader(train_set, dataset_opt, phase)
            opt['len_train_dataloader'] = len(train_loader)

            # éªŒè¯ç¬¬ä¸€ä¸ªæ‰¹æ¬¡æ˜¯å¦åŒ…å«ç‰©ç†æ•°æ®
            if dataset_opt.get('load_physical_data', False):
                try:
                    first_batch = next(iter(train_loader))
                    if 'physical_data' in first_batch:
                        print(f"   âœ… æˆåŠŸåŠ è½½ç‰©ç†æ•°æ®ï¼Œå½¢çŠ¶: {first_batch['physical_data'].shape}")
                    else:
                        print(f"   âš ï¸  æ•°æ®æ‰¹æ¬¡ä¸­æœªæ‰¾åˆ°physical_dataå­—æ®µ")
                except Exception as e:
                    print(f"   âŒ éªŒè¯ç‰©ç†æ•°æ®å¤±è´¥: {e}")

        elif phase == 'val' and args.phase != 'test':
            print("Creating [val] change-detection dataloader.")
            val_set = Data.create_cd_dataset(dataset_opt, phase)
            val_loader = Data.create_cd_dataloader(val_set, dataset_opt, phase)
            opt['len_val_dataloader'] = len(val_loader)
        
        elif phase == 'test' and args.phase == 'test':
            print("Creating [test] change-detection dataloader.")
            test_set = Data.create_cd_dataset(dataset_opt, phase)
            test_loader = Data.create_cd_dataloader(test_set, dataset_opt, phase)
            opt['len_test_dataloader'] = len(test_loader)
    
    logger.info('Initial Dataset Finished')

    # åŠ è½½æ¨¡å‹
    print("ğŸ”„ åŠ è½½æ‰©æ•£æ¨¡å‹...")
    diffusion = Model.create_model(opt)
    logger.info('Initial Diffusion Model Finished')

    # å¤„ç†DataParallel
    if isinstance(diffusion.netG, nn.DataParallel):
        diffusion.netG = diffusion.netG.module
        print("å·²è§£åŒ…diffusionæ¨¡å‹çš„DataParallel")

    # å¤šGPUè®¾ç½®
    if torch.cuda.device_count() > 1:
        print(f"ä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPUè¿›è¡Œè®­ç»ƒ")
        diffusion.netG = diffusion.netG.cuda()
        diffusion.netG = nn.DataParallel(diffusion.netG, device_ids=[0, 1, 2, 3])
        
        # é€‚åº¦å¢åŠ batch size
        for phase in opt['datasets']:
            if 'batch_size' in opt['datasets'][phase]:
                original_bs = opt['datasets'][phase]['batch_size']
                # å¯ä»¥æ ¹æ®GPUæ•°é‡è°ƒæ•´
                # opt['datasets'][phase]['batch_size'] = original_bs * 2
                print(f"{phase} batch_size: {original_bs}")

    # è®¾ç½®å™ªå£°è°ƒåº¦
    diffusion.set_new_noise_schedule(
        opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])
    
    # åˆ›å»ºå˜åŒ–æ£€æµ‹æ¨¡å‹
    print("ğŸ”„ åŠ è½½å˜åŒ–æ£€æµ‹æ¨¡å‹...")
    # change_detection = Model.create_CD_model(opt)
    # ç¡®ä¿ä½¿ç”¨æ–°çš„CDæ¨¡å‹ç±»
    try:
        # åˆ›å»ºå˜åŒ–æ£€æµ‹æ¨¡å‹
        print("ğŸ”„ åŠ è½½å˜åŒ–æ£€æµ‹æ¨¡å‹...")
        change_detection = Model.create_CD_model(opt)
        
        # ç¡®ä¿å…¼å®¹æ€§
        change_detection = ensure_cd_model_compatibility(change_detection, opt)
        
        # éªŒè¯æ¨¡å‹
        print(f"âœ… æˆåŠŸåˆ›å»ºCDæ¨¡å‹: {change_detection.__class__.__name__}")
        
        # æ£€æŸ¥ç‰©ç†æŸå¤±æ”¯æŒ
        if opt['model_cd'].get('loss_type') == 'physics_constrained':
            if hasattr(change_detection, 'criterion'):
                print(f"âœ… ç‰©ç†æŸå¤±å‡½æ•°å·²é…ç½®: {change_detection.criterion.__class__.__name__}")
            else:
                print("âš ï¸  è­¦å‘Šï¼šæ¨¡å‹å¯èƒ½ä¸æ”¯æŒç‰©ç†æŸå¤±")
        
    except Exception as e:
        print(f"âŒ CDæ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

    # åˆå§‹åŒ–æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ªå™¨ï¼ˆå¦‚æœæ–°æ¨¡å‹æ²¡æœ‰ï¼‰
    if not hasattr(change_detection, 'running_metric'):
        print("ğŸ”§ ä¸ºCDæ¨¡å‹æ·»åŠ æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ªå™¨...")
        from misc.metric_tools import ConfuseMatrixMeter
        change_detection.running_metric = ConfuseMatrixMeter(n_class=opt['model_cd']['out_channels'])
        
        # æ·»åŠ æ›´æ–°æŒ‡æ ‡çš„æ–¹æ³•
        def _update_metric(self):
            if hasattr(self, 'change_prediction') and hasattr(self, 'label'):
                G_pred = self.change_prediction.detach()
                G_pred = torch.argmax(G_pred, dim=1)
                current_score = self.running_metric.update_cm(
                    pr=G_pred.cpu().numpy(), 
                    gt=self.label.detach().cpu().numpy()
                )
                return current_score
            return 0.0
        
        change_detection._update_metric = lambda: _update_metric(change_detection)
        print("âœ… æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ªå™¨æ·»åŠ å®Œæˆ")

    # è®¾ç½®æ•°æ®é›†é•¿åº¦ä¿¡æ¯
    if 'len_train_dataloader' in opt:
        change_detection.len_train_dataloader = opt["len_train_dataloader"]
    if 'len_val_dataloader' in opt:
        change_detection.len_val_dataloader = opt["len_val_dataloader"]

    print("ğŸš€ å˜åŒ–æ£€æµ‹æ¨¡å‹åˆå§‹åŒ–å®Œæˆ\n")
    
    # ğŸ”§ å¼ºåˆ¶è®¾å¤‡ä¸€è‡´æ€§è®¾ç½®
    if torch.cuda.is_available():
        target_device = torch.device('cuda:0')
        
        # ç¡®ä¿æ‰©æ•£æ¨¡å‹åœ¨GPU
        if isinstance(diffusion.netG, nn.DataParallel):
            diffusion.netG.module = diffusion.netG.module.to(target_device)
        else:
            diffusion.netG = diffusion.netG.to(target_device)
        
        # ç¡®ä¿å˜åŒ–æ£€æµ‹æ¨¡å‹åœ¨GPU
        if hasattr(change_detection, 'netCD') and change_detection.netCD is not None:
            if isinstance(change_detection.netCD, nn.DataParallel):
                change_detection.netCD.module = change_detection.netCD.module.to(target_device)
            else:
                change_detection.netCD = change_detection.netCD.to(target_device)
        
        print(f"âœ… å¼ºåˆ¶è®¾å¤‡è®¾ç½®å®Œæˆ: {target_device}")
    
    # å¤„ç†CDæ¨¡å‹çš„DataParallel
    if hasattr(change_detection, 'netCD') and change_detection.netCD is not None:
        if isinstance(change_detection.netCD, nn.DataParallel):
            change_detection.netCD = change_detection.netCD.module
            print("å·²è§£åŒ…CDæ¨¡å‹çš„DataParallel")
        
        if torch.cuda.device_count() > 1:
            change_detection.netCD = change_detection.netCD.cuda()

    # è®¾ç½®è®­ç»ƒä¼˜åŒ–
    use_amp = setup_training_optimization(diffusion, change_detection)
    
    # åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨
    performance_monitor = PerformanceMonitor()

    print("ğŸ” è¿›è¡Œæœ€ç»ˆé…ç½®éªŒè¯...")
    
    # éªŒè¯æ•°æ®åŠ è½½
    try:
        sample_batch = next(iter(train_loader))
        print(f"âœ… æ•°æ®åŠ è½½æ­£å¸¸ - æ‰¹æ¬¡å¤§å°: {sample_batch['A'].shape[0]}")
        
        required_keys = ['A', 'B', 'L']
        if opt['model_cd'].get('loss_type') == 'physics_constrained':
            required_keys.append('physical_data')
        
        missing_keys = [k for k in required_keys if k not in sample_batch]
        if missing_keys:
            print(f"âš ï¸  æ•°æ®æ‰¹æ¬¡ç¼ºå°‘å­—æ®µ: {missing_keys}")
        else:
            print(f"âœ… æ•°æ®æ‰¹æ¬¡åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ")
            
    except Exception as e:
        print(f"âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
    
    # éªŒè¯æ¨¡å‹å‰å‘ä¼ æ’­
    try:
        with torch.no_grad():
            process_batch_efficiently(sample_batch, diffusion, change_detection, 
                                    opt, "test", 0)
        print("âœ… æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âš ï¸  æ¨¡å‹å‰å‘ä¼ æ’­æµ‹è¯•å¤±è´¥: {e}")
        print("   å°†åœ¨å®é™…è®­ç»ƒä¸­å°è¯•æ¢å¤")
    
    print("ğŸš€ æ‰€æœ‰è®¾ç½®å®Œæˆï¼Œå¼€å§‹è®­ç»ƒ...\n")

    #################
    # è®­ç»ƒå¾ªç¯ #
    #################
    n_epoch = opt['train']['n_epoch']
    best_mF1 = 0.0
    start_epoch = 0

    if opt['phase'] == 'train':
        # éªŒè¯è®¾å¤‡è®¾ç½®
        device = next(diffusion.netG.parameters()).device
        print(f"è®¾å¤‡æ£€æŸ¥: æ¨¡å‹åœ¨ {device}")
        
        if device.type == 'cpu' and torch.cuda.is_available():
            target_device = torch.device('cuda:0')
            print(f"å¼ºåˆ¶å°†æ¨¡å‹ä» {device} ç§»åŠ¨åˆ° {target_device}")
            diffusion.netG = diffusion.netG.to(target_device)
            change_detection.netCD = change_detection.netCD.to(target_device)
            device = next(diffusion.netG.parameters()).device
            print(f"ç§»åŠ¨åéªŒè¯: æ¨¡å‹ç°åœ¨åœ¨ {device}")

        for current_epoch in range(start_epoch, n_epoch):
            epoch_start_time = time.time()
            change_detection._clear_cache()
            
            train_result_path = f'{opt["path"]["results"]}/train/{current_epoch}'
            os.makedirs(train_result_path, exist_ok=True)
            
            ################
            ### è®­ç»ƒé˜¶æ®µ ###
            ################
            print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ Epoch {current_epoch}/{n_epoch-1}")
            message = f'å­¦ä¹ ç‡: {change_detection.optCD.param_groups[0]["lr"]:.7f}'
            logger.info(message)
            
            for current_step, train_data in enumerate(train_loader):
                step_start_time = time.time()
                
                # é«˜æ•ˆæ‰¹é‡å¤„ç†
                process_batch_efficiently(train_data, diffusion, change_detection, opt, "train")
                
                # å®‰å…¨çš„è®­ç»ƒæ­¥éª¤
                success = execute_training_step(change_detection, current_epoch)
                
                if not success:
                    print(f"è·³è¿‡æ­¥éª¤ {current_step}")
                    continue
                
                # è®°å½•æ€§èƒ½
                step_time = time.time() - step_start_time
                memory_mb = torch.cuda.memory_allocated() / 1024**2 if torch.cuda.is_available() else 0
                performance_monitor.log_step(step_time, memory_mb)
                
                # ä¼˜åŒ–çš„æ—¥å¿—è¾“å‡º
                optimized_logging(current_step, current_epoch, n_epoch, train_loader, 
                                change_detection, logger, opt, "train", performance_monitor)
                
                # æ–°å¢ï¼šç‰©ç†çº¦æŸæŸå¤±è¯¦ç»†ä¿¡æ¯è®°å½•ï¼ˆå¯é€‰ï¼‰
                if current_step % opt['train']['train_print_freq'] == 0:
                    if hasattr(change_detection, 'get_physics_constraint_details'):
                        try:
                            physics_details = change_detection.get_physics_constraint_details()
                            if physics_details:
                                print(f"   ğŸ“Š ç‰©ç†çº¦æŸæŸå¤±åˆ†è§£: {physics_details}")
                        except:
                            pass
                
                # ä¿å­˜å¯è§†åŒ–ç»“æœï¼ˆå‡å°‘é¢‘ç‡ï¼‰
                save_freq = max(opt['train']['train_print_freq'] * 2, len(train_loader) // 5)
                if current_step % save_freq == 0:
                    try:
                        visuals = change_detection.get_current_visuals()
                        
                        # ç¡®ä¿è®¾å¤‡ä¸€è‡´æ€§
                        device = train_data['A'].device
                        visuals['pred_cm'] = visuals['pred_cm'] * 2.0 - 1.0
                        visuals['gt_cm'] = visuals['gt_cm'] * 2.0 - 1.0
                        
                        pred_cm_expanded = visuals['pred_cm'].unsqueeze(1).repeat(1, 3, 1, 1).to(device)
                        gt_cm_expanded = visuals['gt_cm'].unsqueeze(1).repeat(1, 3, 1, 1).to(device)
                        
                        grid_img = torch.cat((train_data['A'], train_data['B'], 
                                            pred_cm_expanded, gt_cm_expanded), dim=0)
                        grid_img = Metrics.tensor2img(grid_img)
                        
                        Metrics.save_img(grid_img, 
                            f'{train_result_path}/img_A_B_pred_gt_e{current_epoch}_b{current_step}.png')
                    except Exception as e:
                        print(f"ä¿å­˜å¯è§†åŒ–å¤±è´¥: {e}")
                
                # å®šæœŸå†…å­˜æ¸…ç†
                if current_step % 50 == 0:
                    torch.cuda.empty_cache()
            
            ### è®­ç»ƒepochæ€»ç»“ ###
            try:
                change_detection._collect_epoch_states()
                logs = change_detection.get_current_log()
                
                epoch_time = time.time() - epoch_start_time
                message = f'[è®­ç»ƒ Epoch {current_epoch}] mF1={logs["epoch_acc"]:.5f}, ' \
                         f'ç”¨æ—¶={epoch_time/60:.1f}åˆ†é’Ÿ'
                
                print(f"\nâœ… {message}")
                logger.info(message)
                
                # è¯¦ç»†æŒ‡æ ‡
                for k, v in logs.items():
                    tb_logger.add_scalar(f'train/{k}', v, current_epoch)
                
                if wandb_logger:
                    wandb_metrics = {
                        'training/mF1': logs['epoch_acc'],
                        'training/mIoU': logs['miou'],
                        'training/OA': logs['acc'],
                        'training/change-F1': logs['F1_1'],
                        'training/no-change-F1': logs['F1_0'],
                        'training/change-IoU': logs['iou_1'],
                        'training/no-change-IoU': logs['iou_0'],
                        'training/train_step': current_epoch,
                        'training/loss': logs.get('l_cd'),
                    }
                    
                    # æ–°å¢ï¼šè®°å½•ç‰©ç†æŸå¤±åˆ†é‡
                    if 'ce_loss' in logs:
                        wandb_metrics['training/ce_loss'] = logs['ce_loss']
                    if 'slope_constraint' in logs:
                        wandb_metrics['training/slope_constraint'] = logs['slope_constraint']
                    if 'spatial_constraint' in logs:
                        wandb_metrics['training/spatial_constraint'] = logs['spatial_constraint']
                    if 'size_constraint' in logs:
                        wandb_metrics['training/size_constraint'] = logs['size_constraint']
                    if 'geology_constraint' in logs:
                        wandb_metrics['training/geology_constraint'] = logs['geology_constraint']
                    
                    wandb_logger.log_metrics(wandb_metrics)
                    
            except Exception as e:
                print(f"è®­ç»ƒæŒ‡æ ‡æ”¶é›†é”™è¯¯: {e}")
            
            change_detection._clear_cache()
            change_detection._update_lr_schedulers()
            
            ##################
            ### éªŒè¯é˜¶æ®µ ###
            ##################
            if current_epoch % opt['train']['val_freq'] == 0:
                print(f"\nğŸ” å¼€å§‹éªŒè¯ Epoch {current_epoch}")
                val_start_time = time.time()
                
                val_result_path = f'{opt["path"]["results"]}/val/{current_epoch}'
                os.makedirs(val_result_path, exist_ok=True)

                for current_step, val_data in enumerate(val_loader):
                    with torch.no_grad():  # éªŒè¯æ—¶ä¸éœ€è¦æ¢¯åº¦
                        process_batch_efficiently(val_data, diffusion, change_detection, opt, "val")
                        # é€‚é…æ–°çš„testæ¥å£
                        if hasattr(change_detection, '_temp_features_A') and hasattr(change_detection, '_temp_features_B'):
                            change_detection.test(
                                change_detection._temp_features_A,
                                change_detection._temp_features_B
                            )
                            # æ¸…ç†ä¸´æ—¶ç‰¹å¾
                            del change_detection._temp_features_A
                            del change_detection._temp_features_B
                        else:
                            change_detection.test()
                        
                        change_detection._collect_running_batch_states()
                    
                    # éªŒè¯æ—¥å¿—ï¼ˆå‡å°‘é¢‘ç‡ï¼‰
                    optimized_logging(current_step, current_epoch, n_epoch, val_loader, 
                                    change_detection, logger, opt, "val")
                    
                    # éªŒè¯å¯è§†åŒ–ï¼ˆæ›´å°‘é¢‘ç‡ï¼‰
                    if current_step % max(1, len(val_loader) // 3) == 0:
                        try:
                            visuals = change_detection.get_current_visuals()
                            device = val_data['A'].device
                            visuals['pred_cm'] = visuals['pred_cm'] * 2.0 - 1.0
                            visuals['gt_cm'] = visuals['gt_cm'] * 2.0 - 1.0
                            
                            pred_cm_expanded = visuals['pred_cm'].unsqueeze(1).repeat(1, 3, 1, 1).to(device)
                            gt_cm_expanded = visuals['gt_cm'].unsqueeze(1).repeat(1, 3, 1, 1).to(device)
                            
                            grid_img = torch.cat((val_data['A'], val_data['B'], 
                                                pred_cm_expanded, gt_cm_expanded), dim=0)
                            grid_img = Metrics.tensor2img(grid_img)
                            
                            Metrics.save_img(grid_img, 
                                f'{val_result_path}/img_A_B_pred_gt_e{current_epoch}_b{current_step}.png')
                        except Exception as e:
                            print(f"éªŒè¯å¯è§†åŒ–å¤±è´¥: {e}")

                ### éªŒè¯æ€»ç»“ ### 
                try:
                    change_detection._collect_epoch_states()
                    logs = change_detection.get_current_log()
                    
                    val_time = time.time() - val_start_time
                    message = f'[éªŒè¯ Epoch {current_epoch}] mF1={logs["epoch_acc"]:.5f}, ' \
                            f'ç”¨æ—¶={val_time/60:.1f}åˆ†é’Ÿ'
                    
                    print(f"âœ… {message}")
                    logger.info(message)
                    
                    for k, v in logs.items():
                        tb_logger.add_scalar(f'val/{k}', v, current_epoch)

                    # ğŸ” è¯¦ç»†çš„WandBè°ƒè¯•è®°å½•
                    if wandb_logger:
                        try:
                            # è°ƒè¯•ï¼šæ‰“å°æ‰€æœ‰logs
                            print("\nğŸ” === WandBè°ƒè¯•ä¿¡æ¯ ===")
                            print(f"å½“å‰epoch: {current_epoch}")
                            print(f"best_mF1: {best_mF1} (ç±»å‹: {type(best_mF1)})")
                            print("logså†…å®¹:")
                            for k, v in logs.items():
                                print(f"  {k}: {v} (ç±»å‹: {type(v)})")
                            
                            # å®‰å…¨è½¬æ¢æ‰€æœ‰æŒ‡æ ‡
                            def safe_convert(value, key):
                                if value is None:
                                    print(f"  âš ï¸  {key}: Noneå€¼")
                                    return None
                                try:
                                    if hasattr(value, 'item'):  # PyTorch tensor
                                        result = float(value.item())
                                    else:
                                        result = float(value)
                                    
                                    # æ£€æŸ¥NaNå’Œæ— ç©·å¤§
                                    if result != result or result == float('inf') or result == float('-inf'):
                                        print(f"  âŒ {key}: æ— æ•ˆæ•°å€¼ {result}")
                                        return None
                                    
                                    print(f"  âœ… {key}: {value} â†’ {result}")
                                    return result
                                except Exception as e:
                                    print(f"  âŒ {key}: è½¬æ¢å¤±è´¥ {value} - {e}")
                                    return None
                            
                            # æ„å»ºå®‰å…¨çš„æŒ‡æ ‡å­—å…¸
                            validation_metrics = {}
                            
                            # ä¸»è¦æŒ‡æ ‡
                            for wandb_key, log_key in [
                                ('validation/mF1', 'epoch_acc'),
                                ('validation/loss', 'l_cd'),
                                ('validation/mIoU', 'miou'),
                                ('validation/accuracy', 'acc'),
                                ('validation/change_F1', 'F1_1'),
                                ('validation/no_change_F1', 'F1_0'),
                                ('validation/change_IoU', 'iou_1'),
                                ('validation/no_change_IoU', 'iou_0'),
                            ]:
                                converted = safe_convert(logs.get(log_key), wandb_key)
                                if converted is not None:
                                    validation_metrics[wandb_key] = converted
                            
                            # ç®€åŒ–å‘½åçš„æŒ‡æ ‡
                            for wandb_key, log_key in [
                                ('val_mF1', 'epoch_acc'),
                                ('val_loss', 'l_cd'),
                                ('val_mIoU', 'miou'),
                                ('val_accuracy', 'acc'),
                            ]:
                                converted = safe_convert(logs.get(log_key), wandb_key)
                                if converted is not None:
                                    validation_metrics[wandb_key] = converted
                            
                            # å…¶ä»–æŒ‡æ ‡
                            validation_metrics['epoch'] = current_epoch
                            validation_metrics['validation_step'] = current_epoch
                            
                            # best_mF1
                            converted_best = safe_convert(best_mF1, 'val_best_mF1')
                            if converted_best is not None:
                                validation_metrics['val_best_mF1'] = converted_best
                                validation_metrics['validation/best_mF1'] = converted_best
                            
                            # æ—¶é—´
                            validation_metrics['validation/time_minutes'] = val_time / 60
                            
                            print(f"\nğŸ“Š å°†è¦è®°å½•çš„æŒ‡æ ‡ ({len(validation_metrics)}ä¸ª):")
                            for k, v in validation_metrics.items():
                                print(f"  {k}: {v}")
                            
                            # è®°å½•åˆ°WandB
                            if validation_metrics:
                                wandb_logger.log_metrics(validation_metrics)
                                print(f"\nâœ… WandBè®°å½•æˆåŠŸ: {len(validation_metrics)}ä¸ªæŒ‡æ ‡")
                            else:
                                print("\nâŒ æ²¡æœ‰æœ‰æ•ˆæŒ‡æ ‡å¯è®°å½•")
                            
                            print("ğŸ” === WandBè°ƒè¯•ä¿¡æ¯ç»“æŸ ===\n")
                            
                        except Exception as e:
                            print(f"âŒ WandBè®°å½•é”™è¯¯: {e}")
                            import traceback
                            traceback.print_exc()
                    
                    # æ¨¡å‹ä¿å­˜é€»è¾‘ä¿æŒä¸å˜
                    if logs['epoch_acc'] > best_mF1:
                        is_best_model = True
                        best_mF1 = logs['epoch_acc']
                        print(f"ğŸ‰ æœ€ä½³æ¨¡å‹æ›´æ–°! mF1: {best_mF1:.5f}")
                        logger.info('[éªŒè¯] æœ€ä½³æ¨¡å‹æ›´æ–°ï¼Œä¿å­˜æ¨¡å‹å’Œè®­ç»ƒçŠ¶æ€')
                    else:
                        is_best_model = False
                        logger.info('[éªŒè¯] ä¿å­˜å½“å‰æ¨¡å‹å’Œè®­ç»ƒçŠ¶æ€')

                    change_detection.save_network(current_epoch, is_best_model=is_best_model)
                    
                except Exception as e:
                    print(f"éªŒè¯æŒ‡æ ‡æ”¶é›†é”™è¯¯: {e}")
                
                change_detection._clear_cache()
                print(f"--- è¿›å…¥ä¸‹ä¸€ä¸ªEpoch ---\n")

            if wandb_logger:
                wandb_logger.log_metrics({'epoch': current_epoch})
            
            # Epochç»“æŸæ¸…ç†
            torch.cuda.empty_cache()
                
        print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
        logger.info('è®­ç»ƒç»“æŸ')
        
    else:
        ##################
        ### æµ‹è¯•é˜¶æ®µ ###
        ##################
        logger.info('å¼€å§‹æ¨¡å‹è¯„ä¼°ï¼ˆæµ‹è¯•ï¼‰')
        print("ğŸ” å¼€å§‹æµ‹è¯•...")
        
        test_result_path = f'{opt["path"]["results"]}/test/'
        os.makedirs(test_result_path, exist_ok=True)
        logger_test = logging.getLogger('test')
        change_detection._clear_cache()

        per_sample_metrics_list = [] # <--- æ–°å¢ï¼šåˆå§‹åŒ–ä¸€ä¸ªåˆ—è¡¨æ¥å­˜å‚¨æ¯ä¸ªæ ·æœ¬çš„æŒ‡æ ‡
        
        for current_step, test_data in enumerate(test_loader):
            with torch.no_grad():
                process_batch_efficiently(test_data, diffusion, change_detection, opt, "test")
                
                # é€‚é…æ–°çš„testæ¥å£
                if hasattr(change_detection, '_temp_features_A') and hasattr(change_detection, '_temp_features_B'):
                    change_detection.test(
                        change_detection._temp_features_A,
                        change_detection._temp_features_B
                    )
                    del change_detection._temp_features_A
                    del change_detection._temp_features_B
                else:
                    change_detection.test()
                
                change_detection._collect_running_batch_states()

            # æµ‹è¯•æ—¥å¿—
            if current_step % max(1, len(test_loader) // 10) == 0:
                logs = change_detection.get_current_log()
                message = f'[æµ‹è¯•] Step {current_step}/{len(test_loader)}, ' \
                         f'mF1: {logs["running_acc"]:.5f}'
                print(message)
                logger_test.info(message)

            # ä¿å­˜æµ‹è¯•ç»“æœ
            try:
                visuals = change_detection.get_current_visuals()

                # --- æ–°å¢ï¼šä¸ºæ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬è®¡ç®—å¹¶æ”¶é›†æŒ‡æ ‡ ---
                batch_pred_cm = visuals['pred_cm'] # è·å–æ‰¹é‡çš„é¢„æµ‹å›¾ [N, H, W]
                batch_gt_cm = visuals['gt_cm']   # è·å–æ‰¹é‡çš„çœŸå€¼å›¾ [N, H, W]
                batch_paths = test_data.get('A_path', [f'sample_{current_step}_{i}' for i in range(batch_pred_cm.size(0))]) # è·å–æ ·æœ¬è·¯å¾„æˆ–ç”ŸæˆID

                for i in range(batch_pred_cm.size(0)):
                    pred_sample = batch_pred_cm[i]
                    gt_sample = batch_gt_cm[i]
                    
                    # è°ƒç”¨æ–°å‡½æ•°è®¡ç®—æŒ‡æ ‡
                    sample_metrics = calculate_per_sample_metrics(pred_sample, gt_sample)
                    
                    # æ·»åŠ æ ·æœ¬æ ‡è¯†ç¬¦
                    sample_metrics['sample_id'] = os.path.basename(batch_paths[i])
                    
                    # æ·»åŠ åˆ°æ€»åˆ—è¡¨
                    per_sample_metrics_list.append(sample_metrics)

                visuals['pred_cm'] = visuals['pred_cm'] * 2.0 - 1.0
                visuals['gt_cm'] = visuals['gt_cm'] * 2.0 - 1.0
                
                # å•ç‹¬ä¿å­˜å›¾åƒ
                img_A = Metrics.tensor2img(test_data['A'], out_type=np.uint8, min_max=(-1, 1))
                img_B = Metrics.tensor2img(test_data['B'], out_type=np.uint8, min_max=(-1, 1))
                gt_cm = Metrics.tensor2img(visuals['gt_cm'].unsqueeze(1).repeat(1, 3, 1, 1), 
                                          out_type=np.uint8, min_max=(0, 1))
                pred_cm = Metrics.tensor2img(visuals['pred_cm'].unsqueeze(1).repeat(1, 3, 1, 1), 
                                            out_type=np.uint8, min_max=(0, 1))

                Metrics.save_img(img_A, f'{test_result_path}/img_A_{current_step}.png')
                Metrics.save_img(img_B, f'{test_result_path}/img_B_{current_step}.png')
                Metrics.save_img(pred_cm, f'{test_result_path}/img_pred_cm{current_step}.png')
                Metrics.save_img(gt_cm, f'{test_result_path}/img_gt_cm{current_step}.png')
                
            except Exception as e:
                print(f"æµ‹è¯•ä¿å­˜å¤±è´¥: {e}")

        ### æµ‹è¯•æ€»ç»“ ###
        try:
            change_detection._collect_epoch_states()
            logs = change_detection.get_current_log()
            
            message = f'[æµ‹è¯•æ€»ç»“] mF1={logs["epoch_acc"]:.5f}\n'
            for k, v in logs.items():
                message += f'{k}: {v:.4e} '
            message += '\n'
            
            print(f"âœ… {message}")
            logger_test.info(message)

            # --- æ–°å¢ï¼šä¿å­˜å•æ ·æœ¬æŒ‡æ ‡åˆ°CSVæ–‡ä»¶ ---
            if per_sample_metrics_list:
                metrics_file_path = os.path.join(test_result_path, 'per_sample_metrics.csv')
                # å®šä¹‰CSVæ–‡ä»¶çš„è¡¨å¤´ï¼Œç¡®ä¿ 'sample_id' åœ¨ç¬¬ä¸€åˆ—
                fieldnames = ['sample_id'] + [key for key in per_sample_metrics_list[0].keys() if key != 'sample_id']
                
                with open(metrics_file_path, 'w', newline='', encoding='utf-8') as csvfile:
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(per_sample_metrics_list)
                
                print(f"ğŸ“Š å•æ ·æœ¬è¯¦ç»†æŒ‡æ ‡å·²ä¿å­˜åˆ°: {metrics_file_path}")
            # --- æ–°å¢ä»£ç ç»“æŸ ---

            if wandb_logger:
                wandb_logger.log_metrics({
                    'test/mF1': logs['epoch_acc'],
                    'test/mIoU': logs['miou'],
                    'test/OA': logs['acc'],
                    'test/change-F1': logs['F1_1'],
                    'test/no-change-F1': logs['F1_0'],
                    'test/change-IoU': logs['iou_1'],
                    'test/no-change-IoU': logs['iou_0'],
                })
                
        except Exception as e:
            print(f"æµ‹è¯•æŒ‡æ ‡æ”¶é›†é”™è¯¯: {e}")

        print("ğŸ‰ æµ‹è¯•å®Œæˆ!")
        logger.info('æµ‹è¯•ç»“æŸ')
        
